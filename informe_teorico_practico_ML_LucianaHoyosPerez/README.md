# üìä Proyecto: Predicci√≥n de Deserci√≥n Estudiantil

## üéØ Objetivo

Este proyecto implementa un **pipeline completo de ciencia de datos** para predecir la deserci√≥n estudiantil en la Universidad EAFIT, identificando tempranamente estudiantes en riesgo para aplicar intervenciones oportunas.

El modelo busca predecir:

> **¬øUn estudiante desertar√° de la universidad? (0 = No, 1 = S√≠)**

Se trata de un problema de:

* ‚úÖ Clasificaci√≥n binaria
* ‚úÖ Aprendizaje supervisado
* ‚úÖ Dataset estructurado
* ‚úÖ Datos balanceados en entrenamiento

---

## üë• Informaci√≥n del Proyecto

**Universidad:** EAFIT  
**Curso:** Fundamentos de Aprendizaje Autom√°tico  
**Tipo de Problema:** Clasificaci√≥n binaria supervisada  
**Algoritmo Propuesto:** XGBoost (Gradient Boosting)  
**M√©trica Principal:** **Recall (>80%)**  

### ¬øPor qu√© Recall?

En este problema, un **Falso Negativo** (no detectar a un estudiante que va a desertar) es mucho m√°s costoso que un **Falso Positivo** (falsa alarma). 

- **FN:** Perder un estudiante = ~$6.000 USD en matr√≠cula perdida
- **FP:** Ofrecer ayuda innecesaria = ~$100 USD

**Ratio de costo:** 60:1

Por eso priorizamos **detectar todos los casos de deserci√≥n** aunque tengamos algunas falsas alarmas.

---

# 1Ô∏è‚É£ Definici√≥n del Problema

Se define formalmente el problema en un archivo:

```
data_output_desercion/definicion_problema.json
```

Contiene:

* Objetivo del proyecto
* Impacto esperado
* Tipo de problema (clasificaci√≥n binaria)
* Variables utilizadas
* Algoritmo propuesto (XGBoost)
* M√©trica principal (Recall)
* Justificaci√≥n de la m√©trica

### Variables utilizadas

#### Variables Num√©ricas

* **Promedio:** Promedio acad√©mico acumulado (escala 0.0 - 5.0)
* **Materias_Perdidas:** N√∫mero de materias reprobadas (0 - 6)

#### Variables Categ√≥ricas (Binarias)

* **Becado:** Si el estudiante tiene beca (S√≠/No)

#### Variable Objetivo (Target)

* **Desert√≥:** Si el estudiante desert√≥ (S√≠/No)

---

# 2Ô∏è‚É£ Generaci√≥n y Recolecci√≥n de Datos

## Dataset Sint√©tico Realista

Se gener√≥ un dataset de **500 estudiantes** con las siguientes caracter√≠sticas:

```python
dataset_desercion_estudiantes.csv
```

### L√≥gica de Generaci√≥n

Los datos fueron generados con **correlaciones realistas**:

1. **Promedio bajo ‚Üí Mayor riesgo de deserci√≥n**
   - Promedio < 2.5: Alto riesgo
   - Promedio 3.0-3.5: Riesgo moderado
   - Promedio > 4.0: Bajo riesgo

2. **Materias perdidas ‚Üí Mayor riesgo**
   - Cada materia perdida aumenta el riesgo en ~8%

3. **Beca ‚Üí Efecto protector**
   - Tener beca reduce el riesgo de deserci√≥n en 60%

### Estad√≠sticas del Dataset

| M√©trica | Valor |
|---------|-------|
| Total de estudiantes | 500 |
| Tasa de deserci√≥n | 32.8% (164 estudiantes) |
| Estudiantes becados | 33.0% (165 estudiantes) |
| Rango de IDs | 1000 - 1499 |
| Promedio general | 3.49 |
| Materias perdidas (promedio) | 1.38 |

### Diferencias entre Desertores y No Desertores

| Variable | Desertores | No Desertores | Diferencia |
|----------|-----------|---------------|------------|
| Promedio | 2.99 | 3.73 | **+0.74** |
| Materias perdidas | 2.33 | 0.91 | **+1.42** |
| % Becados | 15.2% | 41.7% | **-26.5 p.p.** |

Esto permite verificar:

* Calidad de los datos ‚úì
* Balance de clases (67.2% / 32.8%)
* Correlaciones realistas ‚úì
* Patrones detectables ‚úì

---

# 3Ô∏è‚É£ An√°lisis Exploratorio de Datos (EDA)

Se realiza un an√°lisis estad√≠stico completo con **script independiente**:

```bash
python eda_desercion_estudiantes.py
```

---

## Tendencia Central

Para variables num√©ricas:

* **Media**
* **Mediana** 
* **Moda**

Archivos generados:

```
eda_output/01_tendencia_central_numericas.csv
```

Para categ√≥ricas:

```
eda_output/01_moda_categoricas.json
eda_output/01_proporciones_categoricas.json
```

**Ejemplo de resultados:**

| Variable | Media | Mediana | Moda |
|----------|-------|---------|------|
| Promedio | 3.49 | 3.52 | 3.40 |
| Materias_Perdidas | 1.38 | 1.00 | 0.00 |

---

## Cuartiles e IQR

Se calcula:

* **Q1** (Percentil 25)
* **Q2** (Mediana)
* **Q3** (Percentil 75)
* **IQR** (Rango Intercuart√≠lico) = Q3 - Q1
* **L√≠mites de outliers:** [Q1 - 1.5√óIQR, Q3 + 1.5√óIQR]

Archivo:

```
eda_output/02_iqr_results.json
```

**Utilidad:** Identifica valores at√≠picos y comprende la dispersi√≥n de los datos.

---

## Percentiles

Se calculan:

* **P10** (10% de los datos est√°n por debajo)
* **P25** (Q1)
* **P50** (Mediana)
* **P75** (Q3)
* **P90** (90% de los datos est√°n por debajo)

Archivo:

```
eda_output/03_percentiles.json
```

**Utilidad:** Entender la distribuci√≥n completa de los datos.

---

## Correlaciones

Se genera:

* **Matriz de correlaci√≥n completa**
* **Heatmap visual** (PNG)
* **Correlaci√≥n Pearson** (lineal)
* **Correlaci√≥n Spearman** (monot√≥nica)

Archivos generados:

```
eda_output/04_heatmap_correlacion.png
eda_output/04_correlation_stats.json
```

### Correlaciones encontradas

| Variable | Pearson | Spearman | Interpretaci√≥n |
|----------|---------|----------|----------------|
| Promedio | -0.51 | -0.53 | **Negativa fuerte:** Promedio bajo ‚Üí Mayor deserci√≥n |
| Materias_Perdidas | +0.67 | +0.69 | **Positiva fuerte:** M√°s materias perdidas ‚Üí Mayor deserci√≥n |
| Becado | -0.29 | -0.29 | **Negativa moderada:** Tener beca ‚Üí Menor deserci√≥n |

Esto permite entender:

* ‚úÖ Qu√© variables impactan m√°s el target
* ‚úÖ Relaciones lineales vs monot√≥nicas
* ‚úÖ Multicolinealidad entre features

---

## Tablas Pivote (Pivot Tables)

Se analizan agregaciones cruzadas:

### Promedio por Beca y Deserci√≥n

```
eda_output/05_pivot_promedio_beca_desercion.csv
```

| Becado | No Desert√≥ | Desert√≥ |
|--------|-----------|---------|
| No | 3.64 | 3.04 |
| S√≠ | 3.99 | 2.77 |

**Insight:** Los becados tienen mejor promedio, pero si desertan, su promedio sigue siendo bajo.

### Materias Perdidas por Beca y Deserci√≥n

```
eda_output/05_pivot_materias_beca_desercion.csv
```

---

## Visualizaciones Est√°ticas (PNG)

Se generan 6 gr√°ficos profesionales:

### 1. Heatmap de Correlaci√≥n

```
eda_output/04_heatmap_correlacion.png
```

Muestra la matriz de correlaci√≥n con colores (rojo = positiva, azul = negativa).

### 2. Histogramas de Distribuci√≥n

```
eda_output/06_histogramas_distribuciones.png
```

4 subplots:
- Promedio por deserci√≥n
- Materias perdidas por deserci√≥n
- Conteo por deserci√≥n
- Deserci√≥n por beca (barras)

### 3. Boxplots por Deserci√≥n

```
eda_output/06_boxplots_por_desercion.png
```

Muestra la distribuci√≥n de Promedio y Materias Perdidas separadas por clase.

### 4. Scatter Plot: Promedio vs Materias

```
eda_output/06_scatter_promedio_materias.png
```

Visualizaci√≥n 2D mostrando la separaci√≥n entre desertores (rojo) y no desertores (azul).

### 5. Barras de Proporciones

```
eda_output/06_barras_proporciones.png
```

### 6. Gr√°fico Stacked

```
eda_output/06_stacked_desercion_beca.png
```

Barras apiladas mostrando deserci√≥n por beca.

---

## Resumen Estad√≠stico por Clase

Se generan estad√≠sticas descriptivas separadas:

```
eda_output/07_resumen_estadistico_por_clase.csv
eda_output/07_comparacion_medias_por_clase.csv
```

**Ejemplo:**

| Estad√≠stica | Desertores | No Desertores |
|-------------|-----------|---------------|
| Promedio (media) | 2.99 | 3.73 |
| Materias (media) | 2.33 | 0.91 |
| Becados (%) | 15.2% | 41.7% |

---

## Identificaci√≥n de Outliers

Se detectan valores at√≠picos usando el m√©todo **IQR**:

```
eda_output/08_outliers_info.json
```

**Criterio:** Un valor es outlier si:
- Est√° por debajo de Q1 - 1.5√óIQR
- Est√° por encima de Q3 + 1.5√óIQR

---

# 4Ô∏è‚É£ Procesamiento de Datos

Script principal:

```bash
python pipeline_desercion_estudiantes.py
```

Se realiza:

### Limpieza

* **Conversi√≥n segura a num√©rico**
* **Imputaci√≥n con mediana** (variables num√©ricas, si hay nulos)
* **Manejo de valores faltantes** en categ√≥ricas

### Encoding

Se convierte:

```python
Becado: S√≠ ‚Üí 1, No ‚Üí 0
Desert√≥: S√≠ ‚Üí 1, No ‚Üí 0
```

**Resultado:** Todas las variables son num√©ricas para el modelo.

---

# 5Ô∏è‚É£ Divisi√≥n del Dataset

Se aplica split estratificado:

```
70% Train (350 muestras)
15% Validation (75 muestras)
15% Test (75 muestras)
```

Con:

```python
stratify=y  # Mantiene la proporci√≥n de clases
random_state=42  # Reproducibilidad
```

Esto garantiza que la proporci√≥n de desertores/no desertores se mantenga en todos los splits.

### Distribuci√≥n de Clases

| Split | Clase 0 (No Desert√≥) | Clase 1 (Desert√≥) |
|-------|---------------------|-------------------|
| Train (antes balanceo) | 235 | 115 |
| Train (despu√©s balanceo) | 115 | 115 |
| Validation | 50 | 25 |
| Test | 51 | 24 |

---

# ‚öñÔ∏è Balanceo de Clases (Solo Train)

Se utiliza **Under-sampling**:

```python
resample(replace=False, n_samples=min_class)
```

* Se reduce la clase mayoritaria al tama√±o de la minoritaria
* Se evita que el modelo se sesgue hacia "No Desert√≥"
* Se mantiene la informaci√≥n m√°s valiosa

### ¬øPor qu√© balancear?

Sin balanceo, el modelo podr√≠a:
- Predecir siempre "No Desert√≥" 
- Obtener 67% de accuracy
- Pero tener 0% de Recall (¬°no detecta a ning√∫n desertor!)

**Importante:**
El balanceo **solo se aplica en entrenamiento**, nunca en validaci√≥n o test (para evaluar en condiciones reales).

---

# üìè Escalado

Se usa **StandardScaler**:

```python
scaler = StandardScaler()
X_train[NUM_COLS] = scaler.fit_transform(X_train[NUM_COLS])
X_val[NUM_COLS] = scaler.transform(X_val[NUM_COLS])
X_test[NUM_COLS] = scaler.transform(X_test[NUM_COLS])
```

### ¬øQu√© hace StandardScaler?

Transforma cada variable a:
- **Media = 0**
- **Desviaci√≥n est√°ndar = 1**

### ¬øPor qu√© escalar?

- El **Promedio** est√° en escala 0-5
- Las **Materias Perdidas** est√°n en escala 0-6
- Sin escalar, el modelo podr√≠a dar m√°s importancia a las materias por tener valores m√°s grandes

### Regla de Oro

- **fit_transform** ‚Üí Solo en train (aprende media y desviaci√≥n)
- **transform** ‚Üí En val y test (usa la media y desviaci√≥n de train)

Esto evita **data leakage** (filtraci√≥n de informaci√≥n del futuro).

---

# 6Ô∏è‚É£ Exportaci√≥n Final

Se exportan los datos procesados en dos formatos:

### Formato Parquet (eficiente)

```
data_output_desercion/X_train.parquet
data_output_desercion/X_val.parquet
data_output_desercion/X_test.parquet
data_output_desercion/y_train.parquet
data_output_desercion/y_val.parquet
data_output_desercion/y_test.parquet
```

### Formato CSV (legible)

```
data_output_desercion/X_train.csv
data_output_desercion/X_val.csv
data_output_desercion/X_test.csv
data_output_desercion/y_train.csv
data_output_desercion/y_val.csv
data_output_desercion/y_test.csv
```

### Metadatos

```
data_output_desercion/processed_schema.json
data_output_desercion/scaler_stats.json
```

Contiene:

* Proporci√≥n de split (70/15/15)
* Balance final de clases
* N√∫mero de muestras por conjunto
* Features utilizadas
* Estad√≠sticas del scaler (media y std)

---

# üìÇ Estructura de Carpetas

```
proyecto-desercion-estudiantil/
‚îÇ
‚îú‚îÄ‚îÄ üìÑ README.md (este archivo)
‚îÇ
‚îú‚îÄ‚îÄ üìä Datos
‚îÇ   ‚îú‚îÄ‚îÄ dataset_desercion_estudiantes.csv (dataset original)
‚îÇ   ‚îî‚îÄ‚îÄ data_output_desercion/ (datos procesados)
‚îÇ       ‚îú‚îÄ‚îÄ definicion_problema.json
‚îÇ       ‚îú‚îÄ‚îÄ descripcion_basica.csv
‚îÇ       ‚îú‚îÄ‚îÄ scaler_stats.json
‚îÇ       ‚îú‚îÄ‚îÄ processed_schema.json
‚îÇ       ‚îú‚îÄ‚îÄ X_train.csv / X_train.parquet
‚îÇ       ‚îú‚îÄ‚îÄ X_val.csv / X_val.parquet
‚îÇ       ‚îú‚îÄ‚îÄ X_test.csv / X_test.parquet
‚îÇ       ‚îú‚îÄ‚îÄ y_train.csv / y_train.parquet
‚îÇ       ‚îú‚îÄ‚îÄ y_val.csv / y_val.parquet
‚îÇ       ‚îî‚îÄ‚îÄ y_test.csv / y_test.parquet
‚îÇ
‚îú‚îÄ‚îÄ üìà EDA (An√°lisis Exploratorio)
‚îÇ   ‚îî‚îÄ‚îÄ eda_output/
‚îÇ       ‚îú‚îÄ‚îÄ 01_tendencia_central_numericas.csv
‚îÇ       ‚îú‚îÄ‚îÄ 01_moda_categoricas.json
‚îÇ       ‚îú‚îÄ‚îÄ 01_proporciones_categoricas.json
‚îÇ       ‚îú‚îÄ‚îÄ 02_iqr_results.json
‚îÇ       ‚îú‚îÄ‚îÄ 03_percentiles.json
‚îÇ       ‚îú‚îÄ‚îÄ 04_heatmap_correlacion.png ‚≠ê
‚îÇ       ‚îú‚îÄ‚îÄ 04_correlation_stats.json
‚îÇ       ‚îú‚îÄ‚îÄ 05_pivot_promedio_beca_desercion.csv
‚îÇ       ‚îú‚îÄ‚îÄ 05_pivot_materias_beca_desercion.csv
‚îÇ       ‚îú‚îÄ‚îÄ 05_pivot_count_beca_desercion.csv
‚îÇ       ‚îú‚îÄ‚îÄ 06_histogramas_distribuciones.png ‚≠ê
‚îÇ       ‚îú‚îÄ‚îÄ 06_boxplots_por_desercion.png ‚≠ê
‚îÇ       ‚îú‚îÄ‚îÄ 06_scatter_promedio_materias.png ‚≠ê
‚îÇ       ‚îú‚îÄ‚îÄ 06_barras_proporciones.png
‚îÇ       ‚îú‚îÄ‚îÄ 06_stacked_desercion_beca.png
‚îÇ       ‚îú‚îÄ‚îÄ 07_resumen_estadistico_por_clase.csv
‚îÇ       ‚îú‚îÄ‚îÄ 07_comparacion_medias_por_clase.csv
‚îÇ       ‚îî‚îÄ‚îÄ 08_outliers_info.json
‚îÇ
‚îî‚îÄ‚îÄ üêç Scripts Python
    ‚îú‚îÄ‚îÄ pipeline_desercion_estudiantes.py (pipeline completo)
    ‚îî‚îÄ‚îÄ eda_desercion_estudiantes.py (solo EDA)
```

---

# üöÄ C√≥mo Usar Este Proyecto

## Requisitos

```bash
pip install pandas numpy matplotlib seaborn scikit-learn
```

## Ejecuci√≥n

### Paso 1: Generar EDA (An√°lisis Exploratorio)

```bash
python eda_desercion_estudiantes.py
```

**Salida:** Carpeta `eda_output/` con estad√≠sticas y visualizaciones

### Paso 2: Ejecutar Pipeline Completo

```bash
python pipeline_desercion_estudiantes.py
```

**Salida:** Carpeta `data_output_desercion/` con datos procesados listos para entrenar

### Paso 3: Entrenar Modelo (pr√≥ximo paso)

```bash
# Pr√≥ximamente
python train_model.py
```

---

# üìä Resultados Esperados

## Insights del EDA

### 1. Promedio Acad√©mico

- **Desertores:** 2.99 (promedio bajo)
- **No Desertores:** 3.73 (promedio alto)
- **Diferencia:** 0.74 puntos
- **Correlaci√≥n:** -0.51 (negativa fuerte)

### 2. Materias Perdidas

- **Desertores:** 2.33 materias
- **No Desertores:** 0.91 materias
- **Diferencia:** 1.42 materias
- **Correlaci√≥n:** +0.67 (positiva fuerte)

### 3. Efecto de la Beca

- **Desertores becados:** 15.2%
- **No desertores becados:** 41.7%
- **Efecto protector:** -26.5 p.p.
- **Correlaci√≥n:** -0.29 (negativa moderada)

### üí° Conclusi√≥n del EDA

> Los desertores tienen **promedios m√°s bajos**, pierden **m√°s materias** y tienen **menor probabilidad de tener beca**. Estos patrones claros sugieren que un modelo de Machine Learning puede predecir la deserci√≥n exitosamente.

---

# üéØ Buenas Pr√°cticas Implementadas

| ‚úÖ Pr√°ctica | Descripci√≥n |
|------------|-------------|
| **Separaci√≥n clara de fases** | EDA, procesamiento y entrenamiento en scripts separados |
| **Sin data leakage** | Scaler fit solo en train, transform en val/test |
| **Balanceo correcto** | Solo en train, nunca en val/test |
| **Estratificaci√≥n** | Split mantiene proporci√≥n de clases |
| **Escalado apropiado** | StandardScaler para variables num√©ricas |
| **Reproducibilidad** | random_state=42 en todos los splits |
| **Documentaci√≥n completa** | EDA con estad√≠sticas y visualizaciones |
| **Exportaci√≥n eficiente** | CSV (legible) + Parquet (eficiente) |
| **Trazabilidad** | Metadatos en JSON |

---

# üìö Pr√≥ximos Pasos

## 7Ô∏è‚É£ Entrenamiento del Modelo

- [ ] Entrenar XGBoost con los datos balanceados
- [ ] Optimizar hiperpar√°metros con Grid Search
- [ ] Validar con conjunto de validaci√≥n
- [ ] Ajustar threshold de decisi√≥n (0.3-0.4 en lugar de 0.5)

## 8Ô∏è‚É£ Evaluaci√≥n

- [ ] Calcular m√©tricas: Recall, Precision, F1-Score, AUC-ROC
- [ ] Generar matriz de confusi√≥n
- [ ] Analizar curva ROC
- [ ] Validar que Recall > 80%
- [ ] Interpretar feature importance

## 9Ô∏è‚É£ Despliegue (Opcional)

- [ ] Serializar modelo (pickle/joblib)
- [ ] Crear API REST (Flask/FastAPI)
- [ ] Dashboard interactivo (Streamlit)

## üîü Monitoreo (Opcional)

- [ ] Detectar data drift
- [ ] Detectar concept drift
- [ ] Reentrenamiento autom√°tico

---

# ü§ù Contribuciones

Este proyecto fue desarrollado como parte del curso **Fundamentos de Aprendizaje Autom√°tico** en la **Universidad EAFIT**.

---

# üìù Licencia

Este proyecto es de uso acad√©mico.

---

# üìß Contacto

Para preguntas o sugerencias sobre este proyecto, contactar a trav√©s de la plataforma acad√©mica de EAFIT.

---

## üéì Aprendizajes Clave

1. **Importancia del EDA:** Un buen an√°lisis exploratorio es fundamental para entender los datos antes de modelar
2. **Balance de clases:** En problemas desbalanceados, el modelo puede sesgar hacia la clase mayoritaria
3. **M√©tricas apropiadas:** Accuracy no siempre es la mejor m√©trica (en este caso, Recall es m√°s importante)
4. **Escalado:** Variables en diferentes escalas pueden sesgar el modelo
5. **Data leakage:** Informaci√≥n del test no debe filtrarse al entrenamiento
6. **Reproducibilidad:** random_state permite replicar resultados

---

**¬°Gracias por revisar este proyecto! üöÄ**
